#!/usr/bin/env python3
import json
import os
import tempfile

def create_test_data():
    """åˆ›å»ºåªåŒ…å«æ ·æœ¬88çš„æµ‹è¯•æ•°æ®"""
    
    # è¯»å–åŸå§‹æ•°æ®
    with open('data/example_constraints.json', 'r') as f:
        data = json.load(f)
    
    # æ‰¾åˆ°æ ·æœ¬88
    sample_88 = data[88]
    
    print(f"=== æ ·æœ¬88ä¿¡æ¯ ===")
    print(f"Example ID: {sample_88['example_id']}")
    print(f"Level: {sample_88['level']}")
    print(f"å­—ç¬¦æ•°: {len(sample_88['instruction'])}")
    print(f"ä¼°ç®—tokens: ~{len(sample_88['instruction'])//4}")
    print()
    
    # åˆ›å»ºæµ‹è¯•ç”¨çš„å•æ ·æœ¬æ–‡ä»¶
    test_data = [sample_88]
    
    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    with open('data/example_constraints_test.json', 'w') as f:
        json.dump(test_data, f, indent=2)
    
    print("âœ… å·²åˆ›å»ºæµ‹è¯•æ•°æ®æ–‡ä»¶: data/example_constraints_test.json")
    return sample_88

def test_ar_models():
    """æµ‹è¯•ARæ¨¡å‹"""
    print("\n=== æµ‹è¯•ARæ¨¡å‹ ===")
    
    # åˆ›å»ºæµ‹è¯•ç”¨çš„APIè¾“å…¥
    os.system("python -c \"from code.utils import convert_to_api_input; convert_to_api_input('data', 'api_input_test', 'example')\"")

    # æµ‹è¯•Mistral
    print("\nğŸ” æµ‹è¯• Mistral-7B-v0.3...")
    cmd = """python code/model_inference_vllm.py \
        --model-path "mistralai/Mistral-7B-v0.3" \
        --constraint_types example \
        --temperature 0.2 \
        --max-tokens 512 \
        --num-gpus 1 \
        --gpus "0" \
        --api_input_path "api_input_test" \
        --api_output_path "api_output_test" \
        --limit_samples 1"""
    
    result = os.system(cmd)
    if result == 0:
        print("âœ… Mistralæµ‹è¯•æˆåŠŸ")
    else:
        print("âŒ Mistralæµ‹è¯•å¤±è´¥")
    
    # æµ‹è¯•DeepSeek
    print("\nğŸ” æµ‹è¯• DeepSeek-7B-base...")
    cmd = """python code/model_inference_vllm.py \
        --model-path "deepseek-ai/deepseek-llm-7b-base" \
        --constraint_types example \
        --temperature 0.2 \
        --max-tokens 512 \
        --num-gpus 1 \
        --gpus "0" \
        --api_input_path "api_input_test" \
        --api_output_path "api_output_test" \
        --limit_samples 1"""
    
    result = os.system(cmd)
    if result == 0:
        print("âœ… DeepSeekæµ‹è¯•æˆåŠŸ")
    else:
        print("âŒ DeepSeekæµ‹è¯•å¤±è´¥")

def test_llada():
    """æµ‹è¯•LLaDAæ¨¡å‹"""
    print("\n=== æµ‹è¯•LLaDAæ¨¡å‹ ===")
    
    cmd = """python code/llada_inference.py \
        --model_path "GSAI-ML/LLaDA-8B-Base" \
        --constraint_types example \
        --temperature 0.2 \
        --max_new_tokens 512 \
        --diffusion_steps 512 \
        --block_length 512 \
        --api_input_path "api_input_test" \
        --api_output_path "api_output_test" \
        --limit_samples 1"""
    
    result = os.system(cmd)
    if result == 0:
        print("âœ… LLaDAæµ‹è¯•æˆåŠŸ")
    else:
        print("âŒ LLaDAæµ‹è¯•å¤±è´¥")

def test_dream():
    """æµ‹è¯•Dreamæ¨¡å‹"""
    print("\n=== æµ‹è¯•Dreamæ¨¡å‹ ===")
    
    cmd = """python code/dream_inference.py \
        --model_path "Dream-org/Dream-v0-Base-7B" \
        --constraint_types example \
        --temperature 0.2 \
        --max_new_tokens 512 \
        --diffusion_steps 512 \
        --api_input_path "api_input_test" \
        --api_output_path "api_output_test" \
        --limit_samples 1"""
    
    result = os.system(cmd)
    if result == 0:
        print("âœ… Dreamæµ‹è¯•æˆåŠŸ")
    else:
        print("âŒ Dreamæµ‹è¯•å¤±è´¥")

def check_outputs():
    """æ£€æŸ¥è¾“å‡ºç»“æœ"""
    print("\n=== æ£€æŸ¥è¾“å‡ºç»“æœ ===")
    
    models = [
        "mistralai/Mistral-7B-v0.3",
        "deepseek-ai/deepseek-llm-7b-base", 
        "GSAI-ML/LLaDA-8B-Base",
        "Dream-org/Dream-v0-Base-7B"
    ]
    
    for model in models:
        output_file = f"api_output_test/{model}/example_constraint.jsonl"
        if os.path.exists(output_file):
            try:
                with open(output_file, 'r') as f:
                    line = f.readline()
                    if line.strip():
                        data = json.loads(line)
                        content = data['choices'][0]['message']['content']
                        print(f"\nâœ… {model}:")
                        print(f"  è¾“å‡ºé•¿åº¦: {len(content)} å­—ç¬¦")
                        print(f"  å‰100å­—ç¬¦: {content[:100]}...")
                    else:
                        print(f"\nâŒ {model}: è¾“å‡ºæ–‡ä»¶ä¸ºç©º")
            except Exception as e:
                print(f"\nâŒ {model}: è¯»å–è¾“å‡ºå¤±è´¥ - {e}")
        else:
            print(f"\nâŒ {model}: è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")

if __name__ == "__main__":
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    sample_88 = create_test_data()
    
    # åˆ›å»ºæµ‹è¯•ç›®å½•
    os.makedirs("api_input_test", exist_ok=True)
    os.makedirs("api_output_test", exist_ok=True)
    
    # è¿è¡Œæµ‹è¯•
    test_ar_models()
    test_llada() 
    test_dream()
    
    # æ£€æŸ¥ç»“æœ
    check_outputs()
    
    print("\n=== æµ‹è¯•å®Œæˆ ===")
    print("å¦‚æœæŸä¸ªæ¨¡å‹å¤±è´¥ï¼Œå¯èƒ½æ˜¯å› ä¸º:")
    print("1. è¾“å…¥å¤ªé•¿ï¼Œè¶…è¿‡æ¨¡å‹contexté™åˆ¶")
    print("2. å†…å­˜ä¸è¶³")
    print("3. æ¨¡å‹åŠ è½½å¤±è´¥")
    print("4. CUDAå†…å­˜ä¸è¶³")
